{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28b9ea5-c5d1-439b-8dfc-76445270d440",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Bayes' theorem?\n",
    "ans-Bayes' theorem is a mathematical formula that describes the probability of an event based on prior knowledge of related events. It is named after the Reverend Thomas Bayes, an 18th-century British statistician and theologian who first formulated the theorem.\n",
    "\n",
    "In its simplest form, Bayes' theorem can be written as:\n",
    "\n",
    "P(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    "where:\n",
    "\n",
    "P(A|B) is the probability of event A given that event B has occurred\n",
    "P(B|A) is the probability of event B given that event A has occurred\n",
    "P(A) is the prior probability of event A occurring (i.e., the probability of A before taking B into account)\n",
    "P(B) is the prior probability of event B occurring (i.e., the probability of B before taking A into account)\n",
    "Bayes' theorem is widely used in fields such as statistics, machine learning, and artificial intelligence to update the probability of an event as new evidence becomes available. It is also a fundamental tool in Bayesian inference, which is a statistical approach that uses probability theory to make inferences about unknown parameters or hypotheses.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688f2165-3c2a-4af1-8a59-57b3d9f6c325",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What is the formula for Bayes' theorem?\n",
    "ans-\n",
    "Bayes' theorem is a mathematical formula that describes the probability of an event based on prior knowledge or information. It is named after the English statistician Thomas Bayes, who developed it in the 18th century. The formula for Bayes' theorem is as follows:\n",
    "\n",
    "P(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    "where:\n",
    "\n",
    "P(A|B) is the probability of event A occurring given that event B has occurred.\n",
    "P(B|A) is the probability of event B occurring given that event A has occurred.\n",
    "P(A) is the prior probability of event A occurring before any new evidence is taken into account.\n",
    "P(B) is the prior probability of event B occurring before any new evidence is taken into account.\n",
    "In other words, Bayes' theorem allows us to update our belief or knowledge about the probability of an event A based on new evidence in the form of event B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995baa6d-0335-4dcd-be5a-1c369301dd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How is Bayes' theorem used in practice?\n",
    "ans-Bayes' theorem is widely used in various fields, including statistics, machine learning, artificial intelligence, and data science. Here are some examples of how Bayes' theorem is used in practice:\n",
    "\n",
    "Medical diagnosis: Bayes' theorem is used to calculate the probability of a patient having a disease based on their symptoms and medical history. This approach is known as Bayesian diagnosis, and it allows doctors to make more accurate diagnoses by incorporating prior knowledge and updating probabilities as new information becomes available.\n",
    "\n",
    "Spam filtering: Bayes' theorem is used in many spam filters to determine whether an email is spam or not. The filter calculates the probability that an email is spam based on the words used in the email and the frequency of those words in known spam emails.\n",
    "\n",
    "Weather forecasting: Bayes' theorem is used in weather forecasting to update the probability of a certain weather event occurring based on new data, such as temperature readings, wind speeds, and cloud cover.\n",
    "\n",
    "Fraud detection: Bayes' theorem is used in fraud detection to calculate the probability that a transaction is fraudulent based on various factors, such as the location of the transaction, the type of transaction, and the amount of money involved.\n",
    "\n",
    "Overall, Bayes' theorem is a powerful tool that allows us to incorporate prior knowledge and update probabilities as new data becomes available. This makes it a valuable tool in many fields where uncertainty and incomplete information are common.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96527f0e-1815-4cd4-a2db-9cf4e4dd64b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9815f9b0-d646-4e45-842e-f02aac90c16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `probability` not found.\n"
     ]
    }
   ],
   "source": [
    "Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
    "ans-Bayes' theorem and conditional probability are closely related. Conditional probability is the probability of an event A given that another event B has occurred, and it is expressed as P(A|B). Bayes' theorem provides a way to calculate conditional probabilities by incorporating prior knowledge.\n",
    "\n",
    "In particular, Bayes' theorem states that the conditional probability of event A given event B can be calculated as the product of the probability of event B given event A, multiplied by the prior probability of event A, divided by the prior probability of event B. Mathematically, this is expressed as:\n",
    "\n",
    "P(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    "This formula allows us to update our belief about the probability of event A given new evidence in the form of event B. In other words, Bayes' theorem provides a way to incorporate prior knowledge into our calculation of conditional probabilities.\n",
    "\n",
    "For example, if we want to know the probability of a person having a certain disease given that they have a positive test result, we can use Bayes' theorem to calculate this probability by taking into account the prevalence of the disease in the population, the accuracy of the test, and the false positive and false negative rates. This calculation allows us to make a more informed decision about the probability of the person having the disease, given the test result.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de283bd-4b70-4483-866b-f5d57df676fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "ans-Choosing which type of Naive Bayes classifier to use for a given problem depends on the nature of the data and the assumptions that can be made about the distribution of the features.\n",
    "\n",
    "There are three main types of Naive Bayes classifiers:\n",
    "\n",
    "Gaussian Naive Bayes: This type of classifier assumes that the continuous features in the data follow a Gaussian or normal distribution. It is commonly used for classification problems with continuous numerical features.\n",
    "\n",
    "Multinomial Naive Bayes: This type of classifier is suitable for discrete count data, such as text data where each feature represents the frequency of a word in a document. It assumes that the features follow a multinomial distribution.\n",
    "\n",
    "Bernoulli Naive Bayes: This type of classifier is also suitable for discrete data, but assumes that the features are binary, representing the presence or absence of a particular feature. It is commonly used for text classification problems where each feature represents the presence or absence of a word in a document.\n",
    "\n",
    "In general, if the data has continuous features, Gaussian Naive Bayes may be the most appropriate choice. If the data has discrete count data, such as text data, Multinomial Naive Bayes may be the most appropriate choice. If the features are binary, Bernoulli Naive Bayes may be the most appropriate choice.\n",
    "\n",
    "However, the choice of classifier also depends on the specific problem and the nature of the data. It is often useful to try out different types of classifiers and compare their performance using cross-validation or other evaluation methods.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21ade2c-1bec-4607-9e6f-2885a5bafcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "A 3 3 4 4 3 3 3\n",
    "B 2 2 1 2 2 2 3\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?\n",
    "ans-\n",
    "To predict the class of a new instance using Naive Bayes, we need to calculate the posterior probability of each class given the values of the features X1=3 and X2=4. Since we are assuming equal prior probabilities for each class, the prior probability of each class is 0.5.\n",
    "\n",
    "To calculate the posterior probability of class A given X1=3 and X2=4, we use Bayes' theorem:\n",
    "\n",
    "P(A|X1=3,X2=4) = P(X1=3,X2=4|A) * P(A) / P(X1=3,X2=4)\n",
    "\n",
    "where P(X1=3,X2=4|A) is the conditional probability of X1=3 and X2=4 given class A, and P(X1=3,X2=4) is the marginal probability of X1=3 and X2=4.\n",
    "\n",
    "We can apply the Naive Bayes assumption, which assumes that the features are conditionally independent given the class. This means that:\n",
    "\n",
    "P(X1=3,X2=4|A) = P(X1=3|A) * P(X2=4|A)\n",
    "\n",
    "We can calculate P(X1=3|A) and P(X2=4|A) from the table:\n",
    "\n",
    "P(X1=3|A) = 4/10 = 0.4\n",
    "P(X2=4|A) = 3/10 = 0.3\n",
    "\n",
    "Therefore,\n",
    "\n",
    "P(X1=3,X2=4|A) = 0.4 * 0.3 = 0.12\n",
    "\n",
    "Similarly, we can calculate the posterior probability of class B given X1=3 and X2=4:\n",
    "\n",
    "P(B|X1=3,X2=4) = P(X1=3,X2=4|B) * P(B) / P(X1=3,X2=4)\n",
    "\n",
    "where P(X1=3,X2=4|B) is the conditional probability of X1=3 and X2=4 given class B.\n",
    "\n",
    "Using the Naive Bayes assumption, we have:\n",
    "\n",
    "P(X1=3,X2=4|B) = P(X1=3|B) * P(X2=4|B)\n",
    "\n",
    "We can calculate P(X1=3|B) and P(X2=4|B) from the table:\n",
    "\n",
    "P(X1=3|B) = 1/7\n",
    "P(X2=4|B) = 1/7\n",
    "\n",
    "Therefore,\n",
    "\n",
    "P(X1=3,X2=4|B) = 1/49\n",
    "\n",
    "Now we need to calculate the marginal probability of X1=3 and X2=4:\n",
    "\n",
    "P(X1=3,X2=4) = P(X1=3,X2=4|A) * P(A) + P(X1=3,X2=4|B) * P(B)\n",
    "\n",
    "= 0.12 * 0.5 + 1/49 * 0.5\n",
    "\n",
    "= 0.0624\n",
    "\n",
    "Finally, we can calculate the posterior probabilities of each class:\n",
    "\n",
    "P(A|X1=3,X2=4) = 0.12 * 0.5 / 0.0624 = 0.962\n",
    "P(B|X1=3,X2=4) = 1/49 * 0.5 / 0.0624 = 0.038\n",
    "\n",
    "Therefore, Naive Bayes would predict that the new instance with features X1=3 and X2=4 belongs to class A, since the posterior probability of class A is much higher than the posterior probability of class B.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "To predict the class of a new instance using Naive Bayes, we need to calculate the posterior probability of each class given the values of the features X1=3 and X2=4. Since we are assuming equal prior probabilities for each class, the prior probability of each class is 0.5.\n",
    "\n",
    "To calculate the posterior probability of class A given X1=3 and X2=4, we use Bayes' theorem:\n",
    "\n",
    "P(A|X1=3,X2=4) = P(X1=3,X2=4|A) * P(A) / P(X1=3,X2=4)\n",
    "\n",
    "where P(X1=3,X2=4|A) is the conditional probability of X1=3 and X2=4 given class A, and P(X1=3,X2=4) is the marginal probability of X1=3 and X2=4.\n",
    "\n",
    "We can apply the Naive Bayes assumption, which assumes that the features are conditionally independent given the class. This means that:\n",
    "\n",
    "P(X1=3,X2=4|A) = P(X1=3|A) * P(X2=4|A)\n",
    "\n",
    "We can calculate P(X1=3|A) and P(X2=4|A) from the table:\n",
    "\n",
    "P(X1=3|A) = 4/10 = 0.4\n",
    "P(X2=4|A) = 3/10 = 0.3\n",
    "\n",
    "Therefore,\n",
    "\n",
    "P(X1=3,X2=4|A) = 0.4 * 0.3 = 0.12\n",
    "\n",
    "Similarly, we can calculate the posterior probability of class B given X1=3 and X2=4:\n",
    "\n",
    "P(B|X1=3,X2=4) = P(X1=3,X2=4|B) * P(B) / P(X1=3,X2=4)\n",
    "\n",
    "where P(X1=3,X2=4|B) is the conditional probability of X1=3 and X2=4 given class B.\n",
    "\n",
    "Using the Naive Bayes assumption, we have:\n",
    "\n",
    "P(X1=3,X2=4|B) = P(X1=3|B) * P(X2=4|B)\n",
    "\n",
    "We can calculate P(X1=3|B) and P(X2=4|B) from the table:\n",
    "\n",
    "P(X1=3|B) = 1/7\n",
    "P(X2=4|B) = 1/7\n",
    "\n",
    "Therefore,\n",
    "\n",
    "P(X1=3,X2=4|B) = 1/49\n",
    "\n",
    "Now we need to calculate the marginal probability of X1=3 and X2=4:\n",
    "\n",
    "P(X1=3,X2=4) = P(X1=3,X2=4|A) * P(A) + P(X1=3,X2=4|B) * P(B)\n",
    "\n",
    "= 0.12 * 0.5 + 1/49 * 0.5\n",
    "\n",
    "= 0.0624\n",
    "\n",
    "Finally, we can calculate the posterior probabilities of each class:\n",
    "\n",
    "P(A|X1=3,X2=4) = 0.12 * 0.5 / 0.0624 = 0.962\n",
    "P(B|X1=3,X2=4) = 1/49 * 0.5 / 0.0624 = 0.038\n",
    "\n",
    "Therefore, Naive Bayes would predict that the new instance with features X1=3 and X2=4 belongs to class A, since the posterior probability of class A is much higher than the posterior probability of class B.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578cbd11-39ad-48a7-a252-6685c5a498cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8af4ad-624e-40f1-9b3d-0299afc88929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a5d64e-412e-4659-a347-4840b838dc59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e2440a-1bd5-4eba-b92e-8c65ae0e724b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db8739d-d974-4639-a1f2-670201579bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
